{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtiwHAJHBpFgOUUchHnjpq"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Store's Weekly Sales Prediction**"
      ],
      "metadata": {
        "id": "HCzymFfxXRyq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWJLN4CZeF19"
      },
      "outputs": [],
      "source": [
        "# Required packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn.metrics as metrics\n",
        "import sklearn.model_selection as model_selection\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load Dataset**"
      ],
      "metadata": {
        "id": "ITHVAYd_WkX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_ds=pd.read_csv('/content/Features_data_set.csv')"
      ],
      "metadata": {
        "id": "kU77OykgfUMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sale_ds=pd.read_csv('/content/sales_data_set.csv')"
      ],
      "metadata": {
        "id": "U2AjAFAwfmFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_ds=pd.read_csv('/content/stores_data_set.csv')"
      ],
      "metadata": {
        "id": "6BDfaZQuf2Nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Departmentwise Sales Prediction**"
      ],
      "metadata": {
        "id": "DJCwhsv-5kKq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dept_sale_df=sale_ds.copy()"
      ],
      "metadata": {
        "id": "shaEAL-V6gwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dept_sale_df.drop('Store',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "8g_tYJmuDHY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dept_sale_df['Date']=pd.to_datetime(dept_sale_df['Date'])\n",
        "dept_sale_df['Week']=dept_sale_df.Date.dt.isocalendar().week\n",
        "dept_sale_df['Year']=dept_sale_df.Date.dt.year\n",
        "dept_sale_df.sort_values(by=['Dept','Date','IsHoliday'],ascending=True)"
      ],
      "metadata": {
        "id": "1vC0ynMJ5g7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Week col is enough for weekly sales prediction day and date is not needed so removing date column\n",
        "dept_sale_df.drop('Date',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "2lLzVDsI7NiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum up all sales for each department\n",
        "dept_sale_df.sort_values(by=['Dept','IsHoliday','Week','Year'],ascending=True)\n",
        "dept_grouped=dept_sale_df.groupby(['Dept','IsHoliday','Week','Year'])\n",
        "\n",
        "dept_sale_df1=dept_grouped['Weekly_Sales'].sum()\n",
        "dept_sale_df1=dept_sale_df1.reset_index(name='Dept_SP')\n"
      ],
      "metadata": {
        "id": "CaL7pfI-D26h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for checking values randomly\n",
        "dept_sale_df1.to_csv('/content/dept_sale.csv',index=False)"
      ],
      "metadata": {
        "id": "KvFv1HEI7H5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing**"
      ],
      "metadata": {
        "id": "AZT-Qm5hW7mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checking null values\n",
        "dept_sale_df1.isnull().sum()"
      ],
      "metadata": {
        "id": "6PlJ8ZyEXh7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dept_sale_df1.IsHoliday.isnull().sum()"
      ],
      "metadata": {
        "id": "43p46ibMAQdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  checking na values\n",
        "dept_sale_df1.isna().sum()"
      ],
      "metadata": {
        "id": "ZrxZxlvN5XfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dept_sale_df1.info()"
      ],
      "metadata": {
        "id": "VIFQjFaUY54_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dept_sale_df1.columns"
      ],
      "metadata": {
        "id": "FTkaDvsffPK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dept_sale_df.IsHoliday.unique()"
      ],
      "metadata": {
        "id": "CG8cl2FFZQwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding IsHoliday object col to numeric form\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "enc=OrdinalEncoder()\n",
        "dept_sale_df1['IsHoliday'] = enc.fit_transform(dept_sale_df1[['IsHoliday']])"
      ],
      "metadata": {
        "id": "uEyMJOy578vE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for duplicates\n",
        "df=dept_sale_df1[dept_sale_df1.duplicated(subset=['Dept','IsHoliday','Week','Year'],keep='first')==True].sort_values(by=['Dept','Week'],ascending=True)\n",
        "df"
      ],
      "metadata": {
        "id": "c8AgttLaeKc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dept_sale_df1.info()"
      ],
      "metadata": {
        "id": "i7_yoDUn7VKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EDA**"
      ],
      "metadata": {
        "id": "GJhBgM7tbzLN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding Outliers**"
      ],
      "metadata": {
        "id": "WB4ZOjeYaxvs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dept_sale_df1.describe()"
      ],
      "metadata": {
        "id": "ziIS0iminJvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(df, column):\n",
        "    plt.figure(figsize=(16,6))\n",
        "    plt.subplot(1,3,1)\n",
        "    sns.boxplot(data=df, x=column)\n",
        "    plt.title(f'Box Plot for {column}')"
      ],
      "metadata": {
        "id": "LFk-Ig5LBqe_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in dept_sale_df1.columns:\n",
        "    plot(dept_sale_df1, i)"
      ],
      "metadata": {
        "id": "oFTPoNQIjk-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the outliers using IQR\n",
        "def findOutliers(data, col):\n",
        "\tQ3 = np.quantile(data[col], 0.75)\n",
        "\tQ1 = np.quantile(data[col], 0.25)\n",
        "\tIQR = Q3 - Q1\n",
        "\n",
        "\tprint(\"IQR value for column %s is: %s\" % (col, IQR))\n",
        "\n",
        "\tlower_range = Q1 - 1.5 * IQR\n",
        "\tupper_range = Q3 + 1.5 * IQR\n",
        "\tx=np.where((data[col] > upper_range) | (data[col] < lower_range))\n",
        "\tprint(col,\":\",lower_range, upper_range,\"Outliers:\",x[0])\n",
        "for i in dept_sale_df1.columns:\n",
        "\tfindOutliers(dept_sale_df1, i)"
      ],
      "metadata": {
        "id": "OkL36kSeLst0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dept_sale_df1"
      ],
      "metadata": {
        "id": "J-i-1raaJjpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model selection**"
      ],
      "metadata": {
        "id": "bU-XsRizJtF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Features split into x and y. x denotes independant feature and y denotes dependant feature and y is target\n",
        "y= dept_sale_df1['Dept_SP']\n",
        "x = dept_sale_df1.drop('Dept_SP', axis =1)"
      ],
      "metadata": {
        "id": "W2iILPeh8OMu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data into train(80%) and test(20%)\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=20)\n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
      ],
      "metadata": {
        "id": "p5XlwDeV8RKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "model_gbr = GradientBoostingRegressor().fit(x_train, y_train)\n",
        "y_pred=model_gbr.predict(x_test)\n",
        "print(\"MAE:\",metrics.mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE:\",metrics.mean_squared_error(y_test, y_pred))\n",
        "print(\"R2 Score:\",metrics.r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "mah9_TOa8R2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model_rfr = RandomForestRegressor().fit(x_train, y_train)\n",
        "y_pred=model_rfr.predict(x_test)\n",
        "print(\"MAE:\",metrics.mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE:\",metrics.mean_squared_error(y_test, y_pred))\n",
        "print(\"R2 Score:\",metrics.r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "il0AgDdlU1ZE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import  DecisionTreeRegressor\n",
        "model_dtr = DecisionTreeRegressor().fit(x_train, y_train)\n",
        "y_pred=model_dtr.predict(x_test)\n",
        "print(\"MAE:\",metrics.mean_absolute_error(y_test, y_pred))\n",
        "print(\"MSE:\",metrics.mean_squared_error(y_test, y_pred))\n",
        "print(\"R2 Score:\",metrics.r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "n36fvIm4NcPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dept_sale_df1.head(5)"
      ],
      "metadata": {
        "id": "NkrMYtk9bfke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test Data**"
      ],
      "metadata": {
        "id": "E2J7v8tlV4NJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data1\n",
        "test_data=np.array([[1,0,1,2010]])\n",
        "y_pred=model_rfr.predict(test_data)\n",
        "y_pred[0]"
      ],
      "metadata": {
        "id": "97NAV-it8OlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dept_sale_df1.tail(5)"
      ],
      "metadata": {
        "id": "vRDzweYC9i7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data2\n",
        "test_data=np.array([[99,1,40,2012]])\n",
        "y_pred=model_rfr.predict(test_data)\n",
        "y_pred[0]"
      ],
      "metadata": {
        "id": "IOCmOY6x9UyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Create Pickle File**"
      ],
      "metadata": {
        "id": "UF_QZU9mCt2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write pickle file  for Department wise sale prediction\n",
        "with open('/content/dept_sale.pkl', 'wb') as f:\n",
        "    pickle.dump(model_rfr, f)"
      ],
      "metadata": {
        "id": "vcdaMwv5CuSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Weekly Sales prediction with markdown and holiday**"
      ],
      "metadata": {
        "id": "xfdgXDpg5bKh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load data**"
      ],
      "metadata": {
        "id": "cBs4j_MqKkxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weekly_sale_ds=sale_ds.copy()"
      ],
      "metadata": {
        "id": "CdynEaeb-d1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weekly_sale_ds['Date']=pd.to_datetime(weekly_sale_ds['Date'])"
      ],
      "metadata": {
        "id": "TV8palxW-JpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weekly_sale_ds.info()"
      ],
      "metadata": {
        "id": "EFSsjJXaqfDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding new col week as its a weekly prediction\n",
        "weekly_sale_ds['Week']=weekly_sale_ds.Date.dt.isocalendar().week\n",
        "weekly_sale_ds['Year']=weekly_sale_ds.Date.dt.year"
      ],
      "metadata": {
        "id": "ififLC9PPSmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Week,year are enough to predict weekly sales\n",
        "weekly_sale_ds.drop('Date',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "n-7rhjarxi1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum up all the Dept's sales for each store\n",
        "weekly_sale_ds.sort_values(by=['Week','Year'],ascending=True)\n",
        "sale_grouped=weekly_sale_ds.groupby(['Store','IsHoliday','Week','Year'])\n",
        "\n",
        "sale_sum=sale_grouped['Weekly_Sales'].sum()\n",
        "sale_sum=sale_sum.reset_index(name='Weekly_SP')\n",
        "sale_sum"
      ],
      "metadata": {
        "id": "RZHjX7hNpMKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_ds1=feature_ds.copy()"
      ],
      "metadata": {
        "id": "CrIRvC7v-2OV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_ds1['Date']=pd.to_datetime(feature_ds1['Date'])\n",
        "feature_ds1.sort_values(by=['Store','Date'],ascending=True)"
      ],
      "metadata": {
        "id": "RQbG6YM2_EhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_ds1['Week']=feature_ds1.Date.dt.isocalendar().week\n",
        "feature_ds1['Year']=feature_ds1.Date.dt.year"
      ],
      "metadata": {
        "id": "NcXU0DjXQKO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_ds1.drop('Date',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "RSO-ZZeqQ17C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.merge(sale_sum, feature_ds1, on=['Store','Week','Year','IsHoliday'])"
      ],
      "metadata": {
        "id": "1a6__6t0BEYt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.info()"
      ],
      "metadata": {
        "id": "Ep8tYebnC1w_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PrePocessing**"
      ],
      "metadata": {
        "id": "edW_ba1aYjEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.isna().sum()"
      ],
      "metadata": {
        "id": "AuRv_okAZB4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill null values with 0 it denotes no markdown given on the week or markdown concept is not introduced for old years\n",
        "merged_df['MarkDown1']=merged_df['MarkDown1'].fillna(0)\n",
        "merged_df['MarkDown2']=merged_df['MarkDown2'].fillna(0)\n",
        "merged_df['MarkDown3']=merged_df['MarkDown3'].fillna(0)\n",
        "merged_df['MarkDown4']=merged_df['MarkDown4'].fillna(0)\n",
        "merged_df['MarkDown5']=merged_df['MarkDown5'].fillna(0)"
      ],
      "metadata": {
        "id": "YBG7SxksCRPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For checking  original sale amount without markdown\n",
        "# merged_df['Expected_SP']=merged_df['Weekly_Actual_SP']+merged_df['MarkDown1']+merged_df['MarkDown2']+merged_df['MarkDown3']+merged_df['MarkDown4']+merged_df['MarkDown5']"
      ],
      "metadata": {
        "id": "mXaBAMVaBcZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df['Unemployment']=merged_df['Unemployment'].fillna(0)\n",
        "merged_df['CPI']=merged_df['CPI'].fillna(0)"
      ],
      "metadata": {
        "id": "0fEEkIWKFbrG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.sort_values(by=['Store','Week','Year'],ascending=True)"
      ],
      "metadata": {
        "id": "bXgnX0sps9X4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for data cross checking\n",
        "merged_df.to_csv('/content/sale_df.csv',index=False)"
      ],
      "metadata": {
        "id": "XggsaQeqDP3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.info()"
      ],
      "metadata": {
        "id": "vfxaSHDqyYjW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Outliers**"
      ],
      "metadata": {
        "id": "7hjW3j30aKXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot(df, column):\n",
        "    plt.figure(figsize=(16,6))\n",
        "    plt.subplot(1,3,1)\n",
        "    sns.boxplot(data=df, x=column)\n",
        "    plt.title(f'Box Plot for {column}')"
      ],
      "metadata": {
        "id": "gxpQLOqgaQNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in merged_df.columns:\n",
        "    plot(merged_df, i)"
      ],
      "metadata": {
        "id": "5GXisKYyab5z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Feature selection**"
      ],
      "metadata": {
        "id": "RGvaCuhVZgd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr_data = merged_df.corr()\n",
        "corr_data"
      ],
      "metadata": {
        "id": "NYbfpXk7yi8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(16,6))\n",
        "sns.heatmap(corr_data,cmap=\"coolwarm\",fmt=\".2f\",annot=True)"
      ],
      "metadata": {
        "id": "dOibmK7IyjBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all column has less than 0.9 so feature has taken for training"
      ],
      "metadata": {
        "id": "SGYXLrqCZ3yV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "enc=OrdinalEncoder()\n",
        "merged_df['IsHoliday'] = enc.fit_transform(merged_df[['IsHoliday']])"
      ],
      "metadata": {
        "id": "w1ebiGpKyAcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.info()"
      ],
      "metadata": {
        "id": "qhDlSxLDyXua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the model**"
      ],
      "metadata": {
        "id": "SeTL6Bewa7h2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y= merged_df['Weekly_SP']\n",
        "x = merged_df.drop('Weekly_SP', axis =1)"
      ],
      "metadata": {
        "id": "jkgj9leJyjEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)\n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
      ],
      "metadata": {
        "id": "sYLnIiKDyjIV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn import metrics"
      ],
      "metadata": {
        "id": "_bdnJubRyjMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "model_rfr = RandomForestRegressor().fit(x_train, y_train)\n",
        "y_pred= model_rfr.predict(x_test)\n",
        "print(metrics.mean_absolute_error(y_test, y_pred))\n",
        "print(metrics.mean_squared_error(y_test, y_pred))\n",
        "metrics.r2_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "LnG8Tz6UiOFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "model_gbr = GradientBoostingRegressor().fit(x_train, y_train)\n",
        "y_pred=model_gbr.predict(x_test)\n",
        "print(metrics.mean_absolute_error(y_test, y_pred))\n",
        "print(metrics.mean_squared_error(y_test, y_pred))\n",
        "metrics.r2_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "6S-HjHeN3Xni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "model_abr = AdaBoostRegressor().fit(x_train, y_train)\n",
        "y_pred= model_abr.predict(x_test)\n",
        "print(metrics.mean_absolute_error(y_test, y_pred))\n",
        "print(metrics.mean_squared_error(y_test, y_pred))\n",
        "metrics.r2_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "z94u4o8BcJWy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Random Forest Regressor has selected for prediction and testing the model with sample data"
      ],
      "metadata": {
        "id": "7OhbZbp4bXrX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.head(2)"
      ],
      "metadata": {
        "id": "qTxq5ZAr330H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data1\n",
        "test_data=np.array([[1,0,1,2010,71.89,2.603,0.0,\t0.0,\t0.0\t,0.0,\t0.0,\t211.671989,\t7.838]])\n",
        "y_pred=model_rfr.predict(test_data)\n",
        "y_pred[0]"
      ],
      "metadata": {
        "id": "7Oqq_PKEzYsE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.tail(2)"
      ],
      "metadata": {
        "id": "CH0ZEv7WzccY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data2\n",
        "test_data=np.array([[45,\t0.0,\t52,54.47,\t4.000,\t1956.28,\t0.0,7.89,\t599.32,\t3990.54,\t192.327265,\t8.667,50]])\n",
        "y_pred=model_rfr.predict(test_data)\n",
        "y_pred[0]"
      ],
      "metadata": {
        "id": "h4fvOMFiz7ZX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write pickle file  for weekly sale prediction\n",
        "with open('/content/weekly_sale.pkl', 'wb') as f:\n",
        "    pickle.dump(model_rfr, f)"
      ],
      "metadata": {
        "id": "yUo0S84cd8qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "date_string='01/12/2024'\n",
        "dt1=datetime.strptime(date_string, \"%d/%m/%Y\")\n",
        "print(dt1)\n",
        "k=dt1.isocalendar().week\n",
        "print(k)\n"
      ],
      "metadata": {
        "id": "slZWy-BY7u04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df.info()"
      ],
      "metadata": {
        "id": "3IO3TjaySew-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Streamlit APP**"
      ],
      "metadata": {
        "id": "QZ4djfq0drCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn.metrics as metrics\n",
        "import sklearn.model_selection as model_selection\n",
        "import pickle\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "\n",
        "#streamlit  page setting\n",
        "icon = Image.open(\"store.jpg\")\n",
        "st.set_page_config(page_title= \"KR Store - Kavitha\",\n",
        "                page_icon= icon,\n",
        "                layout= \"wide\",\n",
        "                initial_sidebar_state= \"expanded\",\n",
        "                )\n",
        "\n",
        "st.subheader(\":blue[KR Store]\")\n",
        "tab1,tab2,tab3=st.tabs([\":blue[Department Sales]\",\":blue[Weekly Sales]\",\":blue[About]\"])\n",
        "\n",
        "with tab1:\n",
        "  col1,col2,col3=st.columns(3)\n",
        "  with col1:\n",
        "    txt_dept=st.number_input(\"Enter Dept No\")\n",
        "  with col2:\n",
        "    txt_date=st.text_input(\"Enter the Date\",datetime.today().strftime(\"%d/%m/%Y\"))\n",
        "    dt1=datetime.strptime(txt_date, \"%d/%m/%Y\")\n",
        "    dept_week=dt1.isocalendar().week\n",
        "    dept_year=dt1.year\n",
        "  with col3:\n",
        "    txt_holiday=st.selectbox(\"Holiday in date entered week\", (\"True\",\"False\"))\n",
        "    if txt_holiday==\"True\":\n",
        "      holiday=0\n",
        "    else:\n",
        "      holiday=1\n",
        "\n",
        "\n",
        "\n",
        "  if st.button(\"Predict\", key=\"Department Sales\"):\n",
        "      # load the regression pickle model\n",
        "      with open('/content/dept_sale.pkl', 'rb') as f:\n",
        "          model_dpt = pickle.load(f)\n",
        "\n",
        "      # make array for all user input values in required order for model prediction\n",
        "      user_data = np.array([[int(txt_dept),int(holiday),int(dept_week),int(dept_year)]])\n",
        "\n",
        "      # model predict the Department sales based on user input\n",
        "      y_pred = model_dpt.predict(user_data)\n",
        "      sale_price = y_pred[0]\n",
        "\n",
        "      # round the value with 2 decimal point\n",
        "      sale_price = round(sale_price, 2)\n",
        "      st.write(\"Department weekly sales: \", sale_price)\n",
        "\n",
        "with tab2:\n",
        "  col4,col5,col6=st.columns(3)\n",
        "  with col4:\n",
        "    txt_store=st.number_input(\"Enter Store No\")\n",
        "    txt_holiday1=st.selectbox(\"Holiday for date entered week\", (\"True\",\"False\"))\n",
        "    txt_temp=st.number_input(\"Enter Temperature in celcius\")\n",
        "    txt_fuel_price=st.number_input(\"Enter Fuel Price\")\n",
        "    if txt_holiday1==\"True\":\n",
        "      week_holiday=0\n",
        "    else:\n",
        "      week_holiday=1\n",
        "  with col5:\n",
        "    txt_Markdown1=st.number_input(\"Enter MarkDown1\")\n",
        "    txt_Markdown2=st.number_input(\"Enter MarkDown2\")\n",
        "    txt_Markdown3=st.number_input(\"Enter MarkDown3\")\n",
        "    txt_Markdown4=st.number_input(\"Enter MarkDown4\")\n",
        "\n",
        "  with col6:\n",
        "    txt_Markdown5=st.number_input(\"Enter MarkDown5\")\n",
        "    txt_CPI=st.number_input(\"Enter CPI\")\n",
        "    txt_unemployment=st.number_input(\"Enter unemployment\")\n",
        "    txt_date1=st.text_input(\"Enter Date\" ,datetime.today().strftime(\"%d/%m/%Y\"))\n",
        "\n",
        "    dt2=datetime.strptime(txt_date1, \"%d/%m/%Y\")\n",
        "    sale_week=dt2.isocalendar().week\n",
        "    sale_year=dt2.year\n",
        "\n",
        "  if st.button(\"Predict\", key=\"Weekly Sales\"):\n",
        "      # load the regression pickle model\n",
        "      with open('/content/weekly_sale.pkl', 'rb') as f:\n",
        "          model_weekly = pickle.load(f)\n",
        "\n",
        "      user_data = np.array([[int(txt_store),int(week_holiday),int(sale_week),int(sale_year),float(txt_temp),\n",
        "                          float(txt_fuel_price),float(txt_Markdown1),float(txt_Markdown2),float(txt_Markdown3),\n",
        "                          float(txt_Markdown4),float(txt_Markdown5),\n",
        "                          float(txt_CPI),float(txt_unemployment)]])\n",
        "\n",
        "      # model predict Sales based on user input\n",
        "      y_pred = model_weekly.predict(user_data)\n",
        "\n",
        "      Week_Sale = y_pred[0]\n",
        "      markdown=float(txt_Markdown1)+float(txt_Markdown2)+float(txt_Markdown3)+ float(txt_Markdown4)+float(txt_Markdown5)\n",
        "      st.write(\"Weekly Sale :\", Week_Sale, \"With Markdown\",markdown)\n",
        "      st.write(\"Expected sale price might be\", Week_Sale+markdown)\n",
        "with tab3:\n",
        "    st.caption(\":blue[Overview:]\")\n",
        "    st.caption(\":blue[Department wise and general weeklly sales prediction for the given store]\")\n",
        "    st.caption(\":blue[Data Cleaning has done for the all the null values ]\")\n",
        "    st.caption(\":blue[Model built for Department wise sales prediction with 4 input features]\")\n",
        "    st.caption(\":blue[Model built for general weekly sales prediction with markdown and holiday as input]\")\n"
      ],
      "metadata": {
        "id": "9lwnj0WAdqIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "id": "gifOlCYy_S_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit"
      ],
      "metadata": {
        "id": "favDTDJCT0sP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "pbMesSgRp2Yn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}