{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAYus1kZeKtwCyVMFDy+xM"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Retail Store's Sales Forecasting**"
      ],
      "metadata": {
        "id": "p27xg1Hkdvrh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Store's/Dept's Weekly Sales Prediction**"
      ],
      "metadata": {
        "id": "-AXTAa2fd66C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jIJ0QDXdfHU"
      },
      "outputs": [],
      "source": [
        "# Required packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import skew\n",
        "import sklearn.metrics as metrics\n",
        "import sklearn.model_selection as model_selection\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Loading**"
      ],
      "metadata": {
        "id": "0T92iSf8eIdO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "store_ds=pd.read_csv('/content/stores_data_set.csv')\n",
        "print(store_ds.shape)\n",
        "store_ds.head(3)"
      ],
      "metadata": {
        "id": "stRkWrNaeQrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sale_ds=pd.read_csv('/content/sales_data_set.csv')\n",
        "print(sale_ds.shape)\n",
        "sale_ds.head(3)"
      ],
      "metadata": {
        "id": "OjfY1bGMeQeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_ds=pd.read_csv('/content/Features_data_set.csv')\n",
        "print(feature_ds.shape)\n",
        "feature_ds.head(3)"
      ],
      "metadata": {
        "id": "ZTV9p61peMie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_ds=feature_ds.sort_values(by=['Date','Store'])  # 183 * 45\n",
        "feature_ds"
      ],
      "metadata": {
        "id": "qZuGjqSPHOmM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **EDA**"
      ],
      "metadata": {
        "id": "2WRk23hMF9ys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Analysis**"
      ],
      "metadata": {
        "id": "YbdYcNhZK8Wt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**split column**"
      ],
      "metadata": {
        "id": "Hd_QtupRtNEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# adding new col week as its a weekly prediction\n",
        "feature_ds['Date']=pd.to_datetime(feature_ds['Date'])\n",
        "feature_ds['Week']=feature_ds.Date.dt.isocalendar().week\n",
        "feature_ds['Year']=feature_ds.Date.dt.year\n",
        "feature_ds.drop('Date',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "pVhe8SAaMPi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Filter data from 2010 to 2012**"
      ],
      "metadata": {
        "id": "5VXm8V0QtT4i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# in store dataset 2010 to 2012 data only there.\n",
        "feature_df=feature_ds.query('Year!=2013').copy()"
      ],
      "metadata": {
        "id": "OI1yyrO-K7-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sale_df=sale_ds.copy()\n",
        "sale_df['Total_Sales']=sale_df.groupby(['Store','Date','IsHoliday']).Weekly_Sales.transform('sum')"
      ],
      "metadata": {
        "id": "pkYeTs5cHLWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sale_ds['Date']=pd.to_datetime(sale_df['Date'])\n",
        "sale_ds['Week']=sale_ds.Date.dt.isocalendar().week\n",
        "sale_ds['Year']=sale_ds.Date.dt.year\n",
        "sale_ds.sort_values(by=['Dept','Date','IsHoliday'],ascending=True)\n",
        "sale_ds.drop('Date',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "hy6w-2eOOmJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum up all sales for each department\n",
        "sale_df=sale_ds.copy()\n",
        "sale_grouped=sale_df.groupby(['Store','IsHoliday','Week','Year'])\n",
        "\n",
        "sale_df=sale_grouped['Weekly_Sales'].sum()\n",
        "sale_df=sale_df.reset_index(name='Total_sales')\n",
        "sale_df"
      ],
      "metadata": {
        "id": "fZBleYd6NQMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Merge dataframes**"
      ],
      "metadata": {
        "id": "ZKLQCW5BtySz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# join both dataframes\n",
        "merge_sale_df=pd.merge(sale_df,feature_df,how='inner',on=['Store','IsHoliday','Week','Year'])"
      ],
      "metadata": {
        "id": "uEeDw1fIMPl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking for duplicates\n",
        "merge_sale_df1=merge_sale_df[merge_sale_df.duplicated(subset=['Store','IsHoliday','Week','Year','Total_sales'],keep='first')==True].sort_values(by=['Store','Week'],ascending=True)\n",
        "merge_sale_df1"
      ],
      "metadata": {
        "id": "KAH5k43cQeVl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# delete duplicates\n",
        "merge_sale_df.drop_duplicates(subset=['Store', 'IsHoliday', 'Week', 'Year', 'Total_sales'], keep='first', inplace=True)"
      ],
      "metadata": {
        "id": "A46jKBB6R3tj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_sales_df=merge_sale_df[['Store','Week','Year','IsHoliday','Temperature','Fuel_Price','CPI','Unemployment','MarkDown1','MarkDown2','MarkDown3','MarkDown4','MarkDown5','Total_sales']].copy()\n",
        "store_sales_df"
      ],
      "metadata": {
        "id": "K7G2P4SpP0cS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this dataset for dept weekly sales prediction\n",
        "dept_sale_df=sale_ds.copy()\n",
        "dept_sale_df"
      ],
      "metadata": {
        "id": "RFFS3dnwTq3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Store's Weekly Sales Prediction**"
      ],
      "metadata": {
        "id": "UyrzCCFoVQ93"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Cleaning/ Pre Processing**"
      ],
      "metadata": {
        "id": "EgvREnV4GBUE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding null values**"
      ],
      "metadata": {
        "id": "UicQGR47GG7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Size\n",
        "print(\"Size: \", store_sales_df.shape)\n",
        "\n",
        "# To check the column names\n",
        "print(\"\\nColumn list: \",store_sales_df.columns)\n",
        "\n",
        "# column information\n",
        "print(\"\\nInfo: \")\n",
        "store_sales_df.info()"
      ],
      "metadata": {
        "id": "ucXOUhC6GHPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "null_data = store_sales_df.isnull().mean()*100\n",
        "print(\"Null values\\n\")\n",
        "pd.DataFrame({\n",
        "    \"column_name\": null_data.index,\n",
        "    \"Null values\":null_data.values\n",
        "}).sort_values(\"Null values\",ascending=False)"
      ],
      "metadata": {
        "id": "YN7wCR3orC5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# description of the column\n",
        "print(\"Description\\n\")\n",
        "store_sales_df.describe()"
      ],
      "metadata": {
        "id": "3cgedrkNrv5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imputation**"
      ],
      "metadata": {
        "id": "WBfJSOKtW3l5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fill the null values\n",
        "store_sales_df['MarkDown1'].fillna(0, inplace=True)\n",
        "store_sales_df['MarkDown2'].fillna(0, inplace=True)\n",
        "store_sales_df['MarkDown3'].fillna(0, inplace=True)\n",
        "store_sales_df['MarkDown4'].fillna(0, inplace=True)\n",
        "store_sales_df['MarkDown5'].fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "qxwHI-elWVsK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Checking Duplicates**"
      ],
      "metadata": {
        "id": "fxTIYEutW72y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Duplicated datapoints: \",store_sales_df.duplicated().sum())"
      ],
      "metadata": {
        "id": "Lwu0ACjmI2xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Number of \"0\" data availablity - sparcity**"
      ],
      "metadata": {
        "id": "B5cYZ2chUfeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# full row zero\n",
        "col_with_zero = []\n",
        "for i in store_sales_df.columns:\n",
        "    perc_zero = (store_sales_df[i]==0).mean()*100\n",
        "    col_with_zero.append((i,perc_zero))\n",
        "\n",
        "zero_percent = pd.DataFrame(col_with_zero,columns=['column_name','zero_percentage']).sort_values(\"zero_percentage\",ascending=False)\n",
        "zero_percent"
      ],
      "metadata": {
        "id": "dnECUeMDUn5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Datatype Change**"
      ],
      "metadata": {
        "id": "ZiBkrp5yYXa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "store_sales_df['IsHoliday'] = store_sales_df['IsHoliday'].astype(int)\n",
        "store_sales_df['Week'] = store_sales_df['Week'].astype(int)"
      ],
      "metadata": {
        "id": "wdTp33gwYaKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_sales_df.info()"
      ],
      "metadata": {
        "id": "nnpQRo_hcdea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_values = store_sales_df['IsHoliday'].unique()\n",
        "print(unique_values)"
      ],
      "metadata": {
        "id": "TMsqnuLec_Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Statistical Analysis**"
      ],
      "metadata": {
        "id": "Ude_9kWtU6Cy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finding Outliers**"
      ],
      "metadata": {
        "id": "A3GtY6iBVENh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**IQR (Interquartile Range Method)**"
      ],
      "metadata": {
        "id": "JGev5XOYXKuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def out_iqr(df , column):\n",
        "    global lower,upper\n",
        "    q25, q75 = np.quantile(df[column], 0.25), np.quantile(df[column], 0.75)\n",
        "    # calculate the IQR\n",
        "    iqr = q75 - q25\n",
        "    cut_off = iqr * 1.5\n",
        "    lower, upper = q25 - cut_off, q75 + cut_off\n",
        "    df1 = df[df[column] > upper]\n",
        "    df2 = df[df[column] < lower]\n",
        "    return print(f'Total number of outliers in {column} :', df1.shape[0]+ df2.shape[0])"
      ],
      "metadata": {
        "id": "9XCCdNAsVA93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iqr_ds=store_sales_df.copy()\n",
        "for i in iqr_ds.columns:\n",
        "  out_iqr(iqr_ds,i)"
      ],
      "metadata": {
        "id": "c1R_FpIDXJyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**outliers visualization  z-scores**"
      ],
      "metadata": {
        "id": "cf32YB3YgnG7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_rows = 5\n",
        "num_cols = 3\n",
        "total_plots = len(store_sales_df.columns)\n",
        "\n",
        "# Calculate the number of plots per figure\n",
        "plots_per_figure = num_rows * num_cols\n",
        "\n",
        "for i in range(0, total_plots, plots_per_figure):\n",
        "    plt.figure(figsize=(15, 10))\n",
        "    for j, column_name in enumerate(store_sales_df.columns[i:i+plots_per_figure]):\n",
        "        plt.subplot(num_rows, num_cols, j + 1)\n",
        "        z_scores = (store_sales_df[column_name] - store_sales_df[column_name].mean()) / store_sales_df[column_name].std()\n",
        "\n",
        "        threshold = 3\n",
        "\n",
        "        plt.scatter(x=range(len(store_sales_df[column_name])), y=store_sales_df[column_name],\n",
        "                    c=np.where(np.abs(z_scores) > threshold, 'red', 'blue'))\n",
        "\n",
        "        plt.title(f'{column_name} Outliers\\n')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "IY4zPzFCa9t9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Skewness**"
      ],
      "metadata": {
        "id": "ORZaU5kyXsTo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "before_transform = store_sales_df.skew()"
      ],
      "metadata": {
        "id": "4nyseqSKXugo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_columns = len(store_sales_df.columns)\n",
        "fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 20))\n",
        "axs = axs.flatten()\n",
        "\n",
        "for i, column_name in enumerate(store_sales_df.columns):\n",
        "\n",
        "    skewness = skew(store_sales_df[column_name])\n",
        "    sns.histplot(store_sales_df[column_name], bins=10, kde=True, color='cyan', ax=axs[i])\n",
        "    axs[i].axvline(np.mean(store_sales_df[column_name]), color='red', linestyle='dashed', linewidth=2, label='Mean')\n",
        "    axs[i].axvline(np.median(store_sales_df[column_name]), color='blue', linestyle='dashed', linewidth=2, label='Median')\n",
        "\n",
        "    if -1 <= skewness <= 1:\n",
        "        res=\"Symmetric distribution.\"\n",
        "    elif skewness > 1:\n",
        "      res=\"Right-skewed distribution.\"\n",
        "    else:\n",
        "        res=\"Left-skewed distribution.\"\n",
        "    axs[i].set_title(f'Histogram for {column_name}\\nSkewness: {skewness:.2f} \\n {res}')\n",
        "    axs[i].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "1QKhZZ-zkJwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_sales_df"
      ],
      "metadata": {
        "id": "xAVQn64UX05n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Engineering**"
      ],
      "metadata": {
        "id": "W4jzxn-hnHrk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Log Transformation**"
      ],
      "metadata": {
        "id": "RtMSRsRmnR5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epsilon = 1\n",
        "store_sales_df1=store_sales_df.copy()\n",
        "store_sales_df['MarkDown1'] = np.log(store_sales_df['MarkDown1']+ epsilon)\n",
        "store_sales_df['MarkDown2'] = np.log(store_sales_df['MarkDown2']+ epsilon)\n",
        "store_sales_df['MarkDown3'] = np.log(store_sales_df['MarkDown3']+ epsilon)\n",
        "store_sales_df['MarkDown4'] = np.log(store_sales_df['MarkDown4']+ epsilon)\n",
        "store_sales_df['MarkDown5'] = np.log(store_sales_df['MarkDown5']+ epsilon)\n",
        "store_sales_df['Temperature'] = np.log(store_sales_df['Temperature'])\n",
        "store_sales_df['Total_sales'] = np.log(store_sales_df['Total_sales'])\n",
        "store_sales_df['Unemployment'] = np.log(store_sales_df['Unemployment'])"
      ],
      "metadata": {
        "id": "qhEe0R04nRJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fill -ve values with mean\n",
        "store_sales_df['MarkDown1']=store_sales_df['MarkDown1'].apply(lambda x: store_sales_df['MarkDown1'].mean() if x <= 0 else x)\n",
        "store_sales_df['MarkDown2']=store_sales_df['MarkDown2'].apply(lambda x: store_sales_df['MarkDown2'].mean() if x <= 0 else x)\n",
        "store_sales_df['MarkDown3']=store_sales_df['MarkDown3'].apply(lambda x: store_sales_df['MarkDown3'].mean() if x <= 0 else x)\n",
        "store_sales_df['Temperature'] = store_sales_df['Temperature'].apply(lambda x: store_sales_df['Temperature'].mean() if x <= 0 else x)"
      ],
      "metadata": {
        "id": "evbwU_2iqkzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_sales_df['MarkDown1'].fillna(store_sales_df['MarkDown1'].mean(),inplace=True)\n",
        "store_sales_df['MarkDown2'].fillna(store_sales_df['MarkDown2'].mean(), inplace=True)\n",
        "store_sales_df['MarkDown3'].fillna(store_sales_df['MarkDown3'].mean(),inplace=True)\n",
        "store_sales_df['MarkDown4'].fillna(store_sales_df['MarkDown4'].mean(), inplace=True)\n",
        "store_sales_df['MarkDown5'].fillna(store_sales_df['MarkDown5'].mean(), inplace=True)\n",
        "store_sales_df['Temperature'].fillna(store_sales_df['Temperature'].mean(), inplace=True)"
      ],
      "metadata": {
        "id": "ZuueRKvhY_mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_sales_df[store_sales_df['MarkDown1']==np.inf]== store_sales_df['MarkDown1'].mean()"
      ],
      "metadata": {
        "id": "2QE_ncj0XCLB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "after_transform = store_sales_df.skew()"
      ],
      "metadata": {
        "id": "fYC8mpzvoSZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Before Transformation\\n\",before_transform)\n",
        "print(\"After Transformation\\n\",after_transform)"
      ],
      "metadata": {
        "id": "JTWmSzXLvN7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Selection**"
      ],
      "metadata": {
        "id": "XJMWfxO_o6Ee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr_data = store_sales_df.corr()\n",
        "plt.figure(figsize=(16,6))\n",
        "sns.heatmap(corr_data,annot=True,cmap=\"coolwarm\",fmt=\".2f\")"
      ],
      "metadata": {
        "id": "DayIRLoMo-Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Selection**"
      ],
      "metadata": {
        "id": "1GPQ9-aGpQms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y= store_sales_df['Total_sales']\n",
        "x = store_sales_df.drop('Total_sales', axis =1)"
      ],
      "metadata": {
        "id": "4qdlDWRopl4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)\n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
      ],
      "metadata": {
        "id": "AVFq02zcpyMS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "store_model_rfr = RandomForestRegressor(random_state=40).fit(x_train, y_train)\n",
        "y_pred= store_model_rfr.predict(x_test)\n",
        "print(\"MAE:\",metrics.mean_absolute_error(y_test, y_pred))\n",
        "mse=metrics.mean_squared_error(y_test, y_pred)\n",
        "rmse=np.sqrt(mse)\n",
        "print(\"MSE:\",mse)\n",
        "print(\"RMSE:\",rmse)\n",
        "print(\"R2 Score:\",metrics.r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "wB7CoOypp37H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "model_gbr = GradientBoostingRegressor().fit(x_train, y_train)\n",
        "y_pred=model_gbr.predict(x_test)\n",
        "print(\"MAE:\",metrics.mean_absolute_error(y_test, y_pred))\n",
        "mse=metrics.mean_squared_error(y_test, y_pred)\n",
        "rmse=np.sqrt(mse)\n",
        "print(\"MSE:\",mse)\n",
        "print(\"RMSE:\",rmse)\n",
        "print(\"R2 Score:\",metrics.r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "J440CcYVqAfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import  DecisionTreeRegressor\n",
        "model_dtr = DecisionTreeRegressor().fit(x_train, y_train)\n",
        "y_pred=model_dtr.predict(x_test)\n",
        "print(\"MAE:\",metrics.mean_absolute_error(y_test, y_pred))\n",
        "mse=metrics.mean_squared_error(y_test, y_pred)\n",
        "rmse=np.sqrt(mse)\n",
        "print(\"MSE:\",mse)\n",
        "print(\"RMSE:\",rmse)\n",
        "print(\"R2 Score:\",metrics.r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "W0pi6hGCp4Da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test"
      ],
      "metadata": {
        "id": "pYbEgqiszNct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test Data**"
      ],
      "metadata": {
        "id": "wKaz0Mclb0jb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data1\n",
        "test_data=np.array([[1,1,2010,0,1.45,2.63,211.67,0.722,0.80,0.46,0.433,0,0]])\n",
        "y_pred=store_model_rfr.predict(test_data)\n",
        "y_pred[0]"
      ],
      "metadata": {
        "id": "eb12SlmUb2w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_sales_df.head(3)"
      ],
      "metadata": {
        "id": "OXVkXsIRjIQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "eF97dKHBzXjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_sales_df.tail(3)"
      ],
      "metadata": {
        "id": "HLihzQhFlEG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data2\n",
        "test_data=np.array([[45,52,2011,1,1.2,3.38,189.06,0.76,2.2,2.45,1.8,1.92,2.03]])\n",
        "y_pred=store_model_rfr.predict(test_data)\n",
        "y_pred[0]"
      ],
      "metadata": {
        "id": "PQWuCIQ4b54H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write pickle file  for weekly sale prediction\n",
        "with open('/content/store_weekly_sale.pkl', 'wb') as f:\n",
        "    pickle.dump(store_model_rfr, f)"
      ],
      "metadata": {
        "id": "sPWy9FRtb8Zw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dept's weekly sales prediction**"
      ],
      "metadata": {
        "id": "4PJXFuoacVDF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PreProcessing**"
      ],
      "metadata": {
        "id": "8c8hP9Xbcerm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "null_data = dept_sale_df.isnull().mean()*100\n",
        "pd.DataFrame({\n",
        "    \"column_name\": null_data.index,\n",
        "    \"Null values\":null_data.values\n",
        "}).sort_values(\"Null values\",ascending=False)"
      ],
      "metadata": {
        "id": "Cw9yVdcfcaYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total Duplicated datapoints: \",dept_sale_df.duplicated().sum())"
      ],
      "metadata": {
        "id": "AH3l5IyRcZAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dept_sale_df.drop_duplicates(subset=['Store', 'IsHoliday', 'Week', 'Year', 'Dept','Weekly_Sales'], keep='first', inplace=True)"
      ],
      "metadata": {
        "id": "vMHF5ZkldJSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# full row zero\n",
        "col_with_zero = []\n",
        "for i in dept_sale_df.columns:\n",
        "    perc_zero = (dept_sale_df[i]==0).mean()*100\n",
        "    col_with_zero.append((i,perc_zero))\n",
        "\n",
        "zero_percent = pd.DataFrame(col_with_zero,columns=['column_name','zero_percentage']).sort_values(\"zero_percentage\",ascending=False)\n",
        "zero_percent"
      ],
      "metadata": {
        "id": "UAbsOLSEc9Mc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dept_sale_df.info()"
      ],
      "metadata": {
        "id": "7We4_GUQdib6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Datatype Change**"
      ],
      "metadata": {
        "id": "bs-MnpD9do_x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dept_sale_df['IsHoliday']=dept_sale_df['IsHoliday'].astype('int')\n",
        "dept_sale_df['Week']=dept_sale_df['Week'].astype('int')"
      ],
      "metadata": {
        "id": "Tf5JaUXQdz4p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dept_sale_df.shape"
      ],
      "metadata": {
        "id": "cOZjNsZvd8k_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dept_sale_df.describe()"
      ],
      "metadata": {
        "id": "WcCVT9AbeAvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dept_sale_df.skew()"
      ],
      "metadata": {
        "id": "gDsf9xeGeEj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in dept_sale_df.columns:\n",
        "    skewness = dept_sale_df[i].skew()\n",
        "    if -1 <= skewness <= 1:\n",
        "        res=\"Symmetric distribution.\"\n",
        "    elif skewness > 1:\n",
        "      res=\"Right-skewed distribution.\"\n",
        "    else:\n",
        "        res=\"Left-skewed distribution.\"\n",
        "    print(i,\" skewness:\",skewness,\" \",res)"
      ],
      "metadata": {
        "id": "eU8GOPnY2LC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dept_sale_df.std()"
      ],
      "metadata": {
        "id": "5wm1JOskeMD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dept_sale_df.hist(figsize=(10,10))"
      ],
      "metadata": {
        "id": "hBLuQY0qeQ6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Selection**"
      ],
      "metadata": {
        "id": "lrh3oQGKejKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corr_data = dept_sale_df.corr()\n",
        "plt.figure(figsize=(16,6))\n",
        "sns.heatmap(corr_data,annot=True,cmap=\"coolwarm\",fmt=\".2f\")"
      ],
      "metadata": {
        "id": "nV0ZyX1KeoIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the outliers using IQR\n",
        "def findOutliers(data, col):\n",
        "\tQ3 = np.quantile(data[col], 0.75)\n",
        "\tQ1 = np.quantile(data[col], 0.25)\n",
        "\tIQR = Q3 - Q1\n",
        "\n",
        "\tprint(\"IQR value for column %s is: %s\" % (col, IQR))\n",
        "\n",
        "\tlower_range = Q1 - 1.5 * IQR\n",
        "\tupper_range = Q3 + 1.5 * IQR\n",
        "\tx=np.where((data[col] > upper_range) | (data[col] < lower_range))\n",
        "\tprint(col,\":\",lower_range, upper_range,\"Outliers:\",x[0])\n",
        "for i in dept_sale_df.columns:\n",
        "\tfindOutliers(dept_sale_df, i)"
      ],
      "metadata": {
        "id": "1jz_zIWYfsVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Selection**"
      ],
      "metadata": {
        "id": "4lRYm22Qlvzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y= dept_sale_df['Weekly_Sales']\n",
        "x = dept_sale_df.drop('Weekly_Sales', axis =1)"
      ],
      "metadata": {
        "id": "YDOt2nAqf3kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting data into train(80%) and test(20%)\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=20)\n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
      ],
      "metadata": {
        "id": "cGxfu0aqgAJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "model_gbr = GradientBoostingRegressor().fit(x_train, y_train)\n",
        "y_pred=model_gbr.predict(x_test)\n",
        "print(\"MAE:\",metrics.mean_absolute_error(y_test, y_pred))\n",
        "mse=metrics.mean_squared_error(y_test, y_pred)\n",
        "rmse=np.sqrt(mse)\n",
        "print(\"MSE:\",mse)\n",
        "print(\"RMSE:\",rmse)\n",
        "print(\"R2 Score:\",metrics.r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "skVOWVMmgAT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "dept_model_rfr = RandomForestRegressor().fit(x_train, y_train)\n",
        "y_pred=dept_model_rfr.predict(x_test)\n",
        "print(\"MAE:\",metrics.mean_absolute_error(y_test, y_pred))\n",
        "mse=metrics.mean_squared_error(y_test, y_pred)\n",
        "rmse=np.sqrt(mse)\n",
        "print(\"MSE:\",mse)\n",
        "print(\"RMSE:\",rmse)\n",
        "print(\"R2 Score:\",metrics.r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "8w1ARoHogAdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import  DecisionTreeRegressor\n",
        "model_dtr = DecisionTreeRegressor().fit(x_train, y_train)\n",
        "y_pred=model_dtr.predict(x_test)\n",
        "print(\"MAE:\",metrics.mean_absolute_error(y_test, y_pred))\n",
        "mse=metrics.mean_squared_error(y_test, y_pred)\n",
        "rmse=np.sqrt(mse)\n",
        "print(\"MSE:\",mse)\n",
        "print(\"RMSE:\",rmse)\n",
        "print(\"R2 Score:\",metrics.r2_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "o9GAoBOkgA8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dept_sale_df.head(3)"
      ],
      "metadata": {
        "id": "vCMXo3A4ipWv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test Data**"
      ],
      "metadata": {
        "id": "8jgWaxR_ga62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data=np.array([[1,1,0,17,2010]])\n",
        "y_pred=dept_model_rfr.predict(test_data)\n",
        "y_pred[0]"
      ],
      "metadata": {
        "id": "Y7vbkpPhgbP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dept_sale_df.tail(3)"
      ],
      "metadata": {
        "id": "IFYPMmiCiygC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data2\n",
        "test_data=np.array([[45,98,0,43,2012]])\n",
        "y_pred=dept_model_rfr.predict(test_data)\n",
        "y_pred[0]"
      ],
      "metadata": {
        "id": "LIXuXH5Jgbdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write pickle file  for Department wise sale prediction\n",
        "with open('/content/dept_sale.pkl', 'wb') as f:\n",
        "    pickle.dump(dept_model_rfr, f)"
      ],
      "metadata": {
        "id": "M9OdLdV-gbuM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_sales_df.head(3)"
      ],
      "metadata": {
        "id": "B6Wo5EMV51A3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Streamlit App**"
      ],
      "metadata": {
        "id": "WnobH345b-CV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn.metrics as metrics\n",
        "import sklearn.model_selection as model_selection\n",
        "import pickle\n",
        "import streamlit as st\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "from scipy.stats import skew\n",
        "\n",
        "\n",
        "#streamlit  page setting\n",
        "icon = Image.open(\"store.jpg\")\n",
        "st.set_page_config(page_title= \"Retail Store - Kavitha\",\n",
        "                page_icon= icon,\n",
        "                layout= \"wide\",\n",
        "                initial_sidebar_state= \"expanded\",\n",
        "                )\n",
        "\n",
        "st.subheader(\":blue[Retail Store Sales Forecasting]\")\n",
        "tab1,tab2,tab3=st.tabs([\":blue[Department]\",\":blue[Store]\",\":blue[About]\"])\n",
        "\n",
        "with tab1:\n",
        "  col1,col2,col3=st.columns(3)\n",
        "  with col1:\n",
        "    txt_d_store=st.number_input(\"Enter Store No\")\n",
        "    txt_dept=st.number_input(\"Enter Dept No\")\n",
        "  with col2:\n",
        "    txt_date=st.text_input(\"Enter the Date\",datetime.today().strftime(\"%d/%m/%Y\"))\n",
        "    dt1=datetime.strptime(txt_date, \"%d/%m/%Y\")\n",
        "    dept_week=dt1.isocalendar().week\n",
        "    dept_year=dt1.year\n",
        "  with col3:\n",
        "    txt_holiday=st.selectbox(\"Holiday in date entered week\", (\"True\",\"False\"))\n",
        "    if txt_holiday==\"True\":\n",
        "      holiday=0\n",
        "    else:\n",
        "      holiday=1\n",
        "\n",
        "\n",
        "\n",
        "  if st.button(\"Predict Weekly Sales\", key=\"Department's WeeklySales\"):\n",
        "      # load the regression pickle model\n",
        "      with open('/content/dept_sale.pkl', 'rb') as f:\n",
        "          model_dpt = pickle.load(f)\n",
        "\n",
        "      # make array for all user input values in required order for model prediction\n",
        "      user_data = np.array([[int(txt_d_store),int(txt_dept),int(holiday),int(dept_week),int(dept_year)]])\n",
        "\n",
        "      # model predict the Department sales based on user input\n",
        "      y_pred = model_dpt.predict(user_data)\n",
        "      d_weekly_sale = y_pred[0]\n",
        "\n",
        "      # round the value with 2 decimal point\n",
        "      d_weekly_sale = round(d_weekly_sale, 2)\n",
        "      st.write(\"Department weekly sales: \", d_weekly_sale)\n",
        "\n",
        "with tab2:\n",
        "  col4,col5,col6=st.columns(3)\n",
        "  with col4:\n",
        "    txt_store=st.number_input(\"Store No\")\n",
        "    txt_date1=st.text_input(\"Date\" ,datetime.today().strftime(\"%d/%m/%Y\"))\n",
        "    txt_holiday1=st.selectbox(\"Holiday\", (\"True\",\"False\"))\n",
        "    txt_temp=st.number_input(\"Temperature in celcius\")\n",
        "\n",
        "    if txt_holiday1==\"True\":\n",
        "      week_holiday=0\n",
        "    else:\n",
        "      week_holiday=1\n",
        "  with col5:\n",
        "    txt_fuel_price=st.number_input(\"Fuel Price\")\n",
        "    txt_CPI=st.number_input(\"CPI\")\n",
        "    txt_unemployment=st.number_input(\"Unemployment\")\n",
        "    txt_Markdown1=st.number_input(\"MarkDown1\")\n",
        "\n",
        "\n",
        "  with col6:\n",
        "    txt_Markdown2=st.number_input(\"MarkDown2\")\n",
        "    txt_Markdown3=st.number_input(\"MarkDown3\")\n",
        "    txt_Markdown4=st.number_input(\"MarkDown4\")\n",
        "    txt_Markdown5=st.number_input(\"MarkDown5\")\n",
        "\n",
        "\n",
        "\n",
        "    dt2=datetime.strptime(txt_date1, \"%d/%m/%Y\")\n",
        "    sale_week=dt2.isocalendar().week\n",
        "    sale_year=dt2.year\n",
        "\n",
        "  if st.button(\"Predict Weekly Sales\", key=\"Weekly Sales\"):\n",
        "      # load the regression pickle model\n",
        "      with open('/content/store_weekly_sale.pkl', 'rb') as f:\n",
        "          model_store = pickle.load(f)\n",
        "\n",
        "      user_data = np.array([[int(txt_store),int(sale_week),int(sale_year),int(week_holiday),np.log(float(txt_temp)),\n",
        "                          float(txt_fuel_price),float(txt_CPI),np.log(float(txt_unemployment)),np.log(float(txt_Markdown1)),\n",
        "                          np.log(float(txt_Markdown2)),np.log(float(txt_Markdown3)),\n",
        "                          np.log(float(txt_Markdown4)),np.log(float(txt_Markdown5)),\n",
        "                          ]])\n",
        "\n",
        "      # model predict Sales based on user input\n",
        "      y_pred = model_store.predict(user_data)\n",
        "\n",
        "      Week_Sale = np.exp(y_pred[0])\n",
        "      markdown=float(txt_Markdown1)+float(txt_Markdown2)+float(txt_Markdown3)+ float(txt_Markdown4)+float(txt_Markdown5)\n",
        "      st.write(\"Store's Weekly Sale :\", Week_Sale, \"With Markdown\",markdown)\n",
        "      st.write(\"Expected sale price might be\", Week_Sale+markdown)\n",
        "with tab3:\n",
        "    st.caption(\":blue[Overview:]\")\n",
        "    st.caption(\":blue[Store/Department weekly sales prediction]\")\n",
        "    st.caption(\":blue[Data Cleaning has done for the all the null values ]\")\n",
        "    st.caption(\":blue[Model built for Department sales prediction with 4 input features]\")\n",
        "    st.caption(\":blue[Model built for general weekly sales prediction with markdown and holiday as input]\")"
      ],
      "metadata": {
        "id": "1Qzdp_hTcBp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "store_sales_df1"
      ],
      "metadata": {
        "id": "keDBWe5f9Vnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install localtunnel"
      ],
      "metadata": {
        "id": "wboSkAvocNsN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install streamlit"
      ],
      "metadata": {
        "id": "3dzK60ttcN4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/app.py &>/content/logs.txt & npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "CTp4zQ2OcOFH"
      },
      "execution_count": 250,
      "outputs": []
    }
  ]
}